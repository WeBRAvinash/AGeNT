    Soft robotic hand exoskeletons can provide assistance while remaining compact, lightweight, and inexpensive but optimal control in parallel with the nonlinear dynamics of the hand remains challenging. In previous works, we developed learning-based optimal control of a soft hand exoskeleton using a robust neuromechanical model of movement from sEMG signals and developed a 3D printable passive anthropomorphic testbed hand for data-driven validation. However, this testbed did not capture volitional movement, requiring extensive study with human participant experiments for holistic validation. In this work, we design and validate an active anthropomorphic testbed controlled by a neuromechanical model parameterized with cursory human data to train data-reference control policies. We validate this Anthropomorphic Generalized Neuromechanical Testbed (AGeNT) by evaluating its 1) representation of musculotendinous dynamics and 2) of neurological inputs and kinematic outputs in a fine motor position and force tracking task and 3) its utility as a testbed to train a robust optimal data-reference control system. We found that AGeNT represented active and passive musculotendinous dynamics of the human hand within 2.95% MAPE, matched human movement trajectories with max deviations less than 17% RMSE and effort trajectories within 1 standard deviation, and yielded a model-free soft robot control policy that reduced human participant effort by up to 90%, proving its potential to minimize human participant experimentation for robust optimal soft exoskeleton control policies.
